{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16128646",
   "metadata": {},
   "source": [
    "# Model Training Experiment\n",
    "\n",
    "This experiment trains either a VGG11 or ResNet18 model on the CIFAR10 or MNIST dataset, and compares the performance of three optimizers:\n",
    "- **DoWG**\n",
    "- **NDoWG**\n",
    "- **Nesterov**\n",
    "\n",
    "We will measure and compare their training and validation accuracy and loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9a1101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from dowg.dowg import DoWG, NDoWG  # Assuming these are implemented in dowg.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417b448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "# User selection for model and dataset\n",
    "model_name = 'VGG11'  # Options: 'VGG11', 'ResNet18'\n",
    "dataset_name = 'MNIST'  # Options: 'CIFAR10', 'MNIST'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436a5475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "if dataset_name == 'CIFAR10':\n",
    "    num_classes = 10\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "elif dataset_name == 'MNIST':\n",
    "    num_classes = 10\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=3),  # For compatibility with VGG/ResNet\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "else:\n",
    "    raise ValueError('Unknown dataset')\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060f3493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model selection\n",
    "def get_model(model_name, num_classes):\n",
    "    if model_name == 'VGG11':\n",
    "        model = models.vgg11(num_classes=num_classes)\n",
    "    elif model_name == 'ResNet18':\n",
    "        model = models.resnet18(num_classes=num_classes)\n",
    "    else:\n",
    "        raise ValueError('Unknown model')\n",
    "    return model\n",
    "\n",
    "model = get_model(model_name, num_classes).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9862bed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation functions\n",
    "def train_and_evaluate(model, optimizer_class, optimizer_kwargs, epochs=10):\n",
    "    model = get_model(model_name, num_classes).to(device)  # fresh model for each optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optimizer_class(model.parameters(), **optimizer_kwargs)\n",
    "    train_losses, test_losses, train_accs, test_accs = [], [], [], []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "        train_loss = running_loss / total\n",
    "        train_acc = correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        test_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in testloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "        test_loss = test_loss / total\n",
    "        test_acc = correct / total\n",
    "        test_losses.append(test_loss)\n",
    "        test_accs.append(test_acc)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")\n",
    "    return train_losses, test_losses, train_accs, test_accs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb8ffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run experiments with each optimizer\n",
    "optimizers = {\n",
    "    'DoWG': (DoWG, {'lr': learning_rate}),\n",
    "    'NDoWG': (NDoWG, {'lr': learning_rate}),\n",
    "    'Nesterov': (optim.SGD, {'lr': learning_rate, 'momentum': 0.9, 'nesterov': True})\n",
    "}\n",
    "results = {}\n",
    "for name, (opt_class, opt_kwargs) in optimizers.items():\n",
    "    print(f\"\\nTraining with {name} optimizer...\")\n",
    "    train_losses, test_losses, train_accs, test_accs = train_and_evaluate(model, opt_class, opt_kwargs, epochs)\n",
    "    results[name] = {\n",
    "        'train_losses': train_losses,\n",
    "        'test_losses': test_losses,\n",
    "        'train_accs': train_accs,\n",
    "        'test_accs': test_accs\n",
    "    }\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12,5))\n",
    "for name in results:\n",
    "    plt.plot(results[name]['test_accs'], label=f'{name} Test Acc')\n",
    "plt.title('Test Accuracy per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
